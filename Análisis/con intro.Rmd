---
title: "Trabajo Final Muestreo"
author: "Fabricio Camacho y Luciana Viscailuz"
output: html_document
date: "2024-06-18"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F,fig.cap = TRUE)

```


# INTRODUCCIÓN


El objetivo de este proyecto es realizar estimaciones de diferentes parámetros a partir de varios de los metodos ya vistos en clase.
Para cumplir el objetivo la obtención de la muestra es una etapa clave, y para esta se comenzó seleccionando una muestra aleatoria de los hogares de Montevideo bajo un
diseño estratificado, por conglomerados y en dos etapas de selección. Siendo las UPM las manzanas y la USM los hogares.
Para la selección de las UPM y posteriormente las USM se combinaron diferentes diseños según lo pautado.
Finalmente, una vez obtenidas las muestras y las estimaciones se realizaron comparaciones obteniendo así diferentes conclusiones.



### Paquetes
```{r, warning=FALSE, message=FALSE, echo=T}
library(tidyverse)
library(survey)
library(srvyr)
library(sampling)
library(here)
library(kableExtra)
library(e1071)
library(moments)


options(scipen = 9999)

```

```{r,warning=FALSE, message=FALSE,}
U <- read_csv(here("Datos/Montevideo GR1.csv"))
```





# Analisis previo

```{r}

summary(U) %>%
  kable() %>%
  kable_styling(position = "center", latex_options = "HOLD_position") %>%  kable_classic_2()

```
### Totales

```{r}
# computamos totales de las variables y N
pop_total = U %>% summarise(Total_personas=sum(cant_personas),
                 Desocupados=sum(desocupados),
                 Ocupados=sum(ocuopados),
                 Pobres=sum(pobre),
                 N=n())%>%
                 kable()%>%
                kable_styling(position = "center", latex_options = "HOLD_position") %>%  kable_classic_2()
pop_total

```

# RESULTADOS



**1. Calcule el tamano de muestra para obtener un margen de error de ±3% a un 95%**
**de confianza para estimar cualquier proporcion poblacional. Asuma un efecto de diseno de 1.5.**

Para obtener el tamaño de muestra para cualquier proporción se utilizó la formula:

  $$n = ((z^2 * p*(1-p))/moe^2)*moe$$ 

Como se pedía un 95% de confianza, $\alpha$ tomó el valor de 0.05. Llevando a que $z_{(1-\sigma)}$  fuera el valor de la distribución normal en el cuantil 0.975.
Posteriormente se asumió que p tomaba el valor de 0.5 y se sustituyó moe (margen de error) por 0.03, tal como pide la letra.
Finalmente el tamaño de la muestra quedó en **1601**

```{r}

n = round((((1.96^2 * 0.5 * (1-0.5)) / 0.03^2) * 1.5 ),0)

```

**2. Con el tamano de muestra calculado en el punto anterior, asigne el mismo por estrato de forma optima, utilizando como variable auxiliar el ingreso del hogar.**

Se comenzó calculando para cada estrato su tamaño y las medidas de resumen (total, promedio y desvío) de la variable auxiliar, ingreso_hog.
Posteriormente, algunos de estos resultados fueron utilizados junto con el tamaño de muestra calculado en el punto anterior para obtener el tamaño de muestra de cada estrato según la asignación optima. 

$$n_h = n \\times \\frac{N_h \\text{sd}_{dU_h}[y]}{\\sum_{h=1}^{H} N_h \\text{sd}_{dU_h}[y]}$$

```{r}


U %>% 
  group_by(estrato) %>% 
  summarise(N=n(),
            tot_ing=sum(ingreso_hog),
            prom_ing=mean(ingreso_hog),
            sd_ig=sd(ingreso_hog),) %>%
            mutate(n_opt=round(n*N*sd_ig/sum(N*sd_ig),0))%>%
            rename(.,N_h=N,
                    Total_ingreso=tot_ing,
                   Promedio_ingreso=prom_ing,
                   SE_ingreso=sd_ig,
                   Tamaño_optimo=n_opt)%>%
            as.data.frame(.)%>%
                 kable()%>%
                kable_styling(position = "center", latex_options = "HOLD_position") %>%  kable_classic_2()




```


```{r, echo=F}
tam = U %>% 
  group_by(estrato) %>% 
  summarise(N=n(),
            tot_ing=sum(ingreso_hog),
            prom_ing=mean(ingreso_hog),
            sd_ig=sd(ingreso_hog),) %>%
            mutate(n_opt=round(n*N*sd_ig/sum(N*sd_ig),0))%>%
            rename(.,N_h=N,
                    Total_ingreso=tot_ing,
                   Promedio_ingreso=prom_ing,
                   SE_ingreso=sd_ig,
                   Tamaño_optimo=n_opt)


```




**3. Seleccione una muestra bajo el diseño propuesto (aleatorio, estratificado, por conglomerados y en 2 etapas de selección).**
**Utilice como semilla el número de grupo al que pertenece.**


Para obtener la muestra final de hogares, se comenzó seleccionando *m* manzanas en cada estrato bajo un diseño PPS sin reemplazo, donde la probabilidad de que cada manzana fuera seleccionada dependía de la cantidad de personas que habitaban en ella, es decir, mientras mayor población existía en la manzana mayor probabilidad tenía esta de ser seleccionada. Dicho *m* se calculó tomando en cuenta el tamaño de muestra óptimo en cada estrato y que posteriormente se iban a extrarer cinco viviendas de cada manzana.

Obtenida la muestra de UPMs de cada estrato, se seleccionaron cinco viviendas de cada manzana bajo un diseño simple.

Finalmente, la muestra de hogares quedó conformada por cada uno de los cinco hogares extraídos de cada una de las manzanas seleccionadas de cada estrato. Se puede afirmar que en la muestra final hay hogares de los diferentes niveles socioeconomicos.



```{r, echo=T, message=F}


Muestra = list("Estrato 1"=0,"Estrato 2"=0,"Estrato 3"=0,"Estrato 4"=0,"Estrato 5"=0)

tamano= tam %>% as.data.frame(.)%>% select(.,Tamaño_optimo) %>% as.vector(.)


for(i in 1:5) {
  
#Primera etapa

m=round(tamano[["Tamaño_optimo"]][i]/5,0) #Cantidad de manzanas que se seleccionan de cada estrato

#Cantidad de personas por UPM (manzana)
U_upm_estrato = U %>% filter(,estrato==i) %>%  group_by(manzana) %>% summarise(MOS=sum(n())) %>% arrange(MOS)


#Se seleccionan m manzanas del estrato
set.seed(1)

s_upm=sampling::strata(data=U_upm_estrato,
                    stratanames = NULL,
                    size=m,
                    method='systematic',
                    pik=U_upm_estrato$MOS)

s_upm = getdata(U_upm_estrato,s_upm) %>% rename(prob_upm=Prob)


#Segunda etapa

#Se seleccionan bajo un Diseño simple 5 hogares de cada manzana seleccionada.

U_usm= U %>% left_join(s_upm %>% select(manzana,prob_upm)) %>% filter(is.na(prob_upm)==FALSE)

U_usm= U_usm %>% arrange(manzana)

set.seed(1)

s= sampling::strata(data=U_usm,
                    stratanames = 'manzana',
                    size=rep(5,m),
                    method='srswor')

s = getdata(U_usm,s) %>% rename(prob_usm=Prob)
  

Muestra[[i]]=s
  
}

S = tibble::as_tibble(rbind(Muestra[[1]],Muestra[[2]],Muestra[[3]],Muestra[[4]],Muestra[[5]])) %>%
  mutate(prob_total=prob_upm*prob_usm,
                w=1/prob_total)



```

**4. Calcule la estimacion puntual del ingreso promedio, proporcion de hogares pobres y total de personas ,a nivel de toda la población**

**Para cada estimacion se debe computar:**
 **- Error estandar (SE)**
 **- Coeficiente de variacion**
 **- Efecto de diseno**
 **- Margenes de error al 95%.**
 
**Interprete los resultados.**
 

Las estimaciones se realizaron tomando en cuenta la muestra final de hogares y el diseño con el que se trabajó.

$$\hat Y_{HT}=\sum\limits_{i\in s} \frac{y_i}{\pi_i}$$ 

donde 

$$\pi=n\frac{x_i}{\sum\limits_{i\in U}x_i}$$

# Seguir


```{r,echo=F}

#Diseño estratificado en dos etapas 
ps_pps = S %>% svydesign(ids=~manzana+ID,
                        strata = ~estrato, 
                     weights=~w,
                     data=.)


#Ingreso promedio

ingreso_promedio_gorro = cross_join( as.data.frame(svymean(~ingreso_hog,ps_pps,deff=T)),
                                     as.data.frame(confint(svymean(~ingreso_hog,ps_pps,deff=T))))%>%
                          rename(.,Estimacion_puntual=mean,SE=ingreso_hog,Deff=deff)%>%
                              mutate(.,CV=SE/Estimacion_puntual)


#Proporcion de hogares pobres


hogares_pobres_gorro = cross_join( as.data.frame(svymean(~pobre,ps_pps,deff=T)),
                                     as.data.frame(confint(svymean(~pobre,ps_pps,deff=T))))%>%
                            rename(.,Estimacion_puntual=mean,SE=pobre,Deff=deff)%>%
                              mutate(.,CV=SE/Estimacion_puntual)


#Total de personas

total_personas_gorro = cross_join( as.data.frame(svytotal(~cant_personas,ps_pps,deff=T)),
                                     as.data.frame(confint(svytotal(~cant_personas,ps_pps,deff=T))))%>%
                          rename(.,Estimacion_puntual=total,SE=cant_personas,Deff=deff)%>%
                              mutate(.,CV=SE/(as.data.frame(svymean(~cant_personas,ps_pps,deff=T))$mean) )

#Totales

estimadores =round(rbind(ingreso_promedio_gorro,hogares_pobres_gorro,total_personas_gorro),3)%>%
  select(.,1,2,6,4,5,3)

rownames(estimadores) <- c("Ingreso promedio","Proporcion hogares pobres","Total de personas")

estimadores%>%
  kable()%>%
  kable_styling(position = "center", latex_options = "HOLD_position")%>%
  kable_classic_2()

```
 

**5. Para computar los errores estándar del punto anterior, ¿qué método para estimar varianza se utilizó?**

Para estimar la varianza se utilizó el método del último conglomerado junto con la linealización de Taylor. En este método se asume que la mayor variabilidad en la estimación proviene de la primera etapa del muestreo y que las manzanas (UPM) son seleccionadas con reposición. Luego el método de la linealización de Taylor realiza una aproximación lineal del estimador y permite estimar la varianza utilizando métodos para estimadores lineales.

Survey, el paquete que se utilizó en el punto anterior por defecto utiliza la formula: 

$$\hat V_{UC}=\frac{1}{n_I\n_I-1}\sum\limits_{i\in s_I}\(hat Y_i*-hat Y)**$$


 **6. Calcule el ingreso per cápita en Montevideo (junto con su error estándar).**
**Indique el tipo de parámetro y qué método fue utilizado por defecto por el paquete survey para la estimación del error estándar.**


En este punto se obtiene un estimador complejo denominado "Ratio", debido a que surge como cociente de dos totales, ingresos totales en Montevideo y cantidad de habitantes. Para realizar su estimación se debió contar previamente con la estimación de dichos totales.

Por defecto, el paquete survey utiliza la "Linealización de Taylor" y se aproxima $\\hat{\\theta}$, el parámetro de interés, por su desarrollo de primer orden. Como se utiliza una aproximación del parámetro, finalmente se obtiene la varianza del pseudo-estimador que es la que se conoce como la aproximación de la varianza.

$$\\hat{V}(\\hat{\\theta}) = \\sum_{i \\in s} \\sum_{j \\in s} \\frac{\\Delta_{ij}}{\\pi_{ij}} \\frac{\\hat{u}_i}{\\pi_i} \\frac{\\hat{u}_j}{\\pi_j}$$

Siendo $\\hat{u}_i=\sum\limits_{q=1}^Q\\hat{a}_q\y_qi  #CAMBIAR FORMULAS POR LA DE V(R)??

Al realizarle la raíz cuadrada a la estimación de la varianza se obtiene finalmente el ${\sigma}$.


```{r, echo=F,message=F}

# Calcular la estimación de razón


ratio_est <- svyratio(numerator = ~ingreso_hog,
                      denominator = ~cant_personas,
                      design = ps_pps)

Ingreso_percapita=bind_cols(as.data.frame(ratio_est$ratio),as.data.frame(sqrt(ratio_est$var)))%>%
  rename(Ingreso_Percapita=cant_personas...1,SE=cant_personas...2)

row.names(Ingreso_percapita)=NULL

Ingreso_percapita

```
**7. Calcule la estimación del error estándar del punto anterior, utilizando dos métodos de remuestreo: Jackknife y Bootstrap (con 1000 réplicas).**

**Compare los resultados obtenidos.**

Jackknife y Bootstrap son dos métodos de remuestreo que tienen como uno de sus objetivos obtener el ${\sigma}$ de estimadores no lineales.
La idea general de estos es que obtienen replicas de forma independiente a partir de la muestra original y posteriormente, para cada una de estas se calcula la estimación del parámetro. La varianza del estimador se obtiene a partir de observar la varianza entre las replicas.

Se comenzó realizando la estimación del error estándar bajo el método de Jackknife. Como el diseño es estratificado, se apliCa Jackknife dentro de cada estrato. En este metodo se obtienen las réplicas eliminando de una unidad a la vez, en este caso, como el diseño es por conglomerados, eliminar una unidad se trauce en eliminar una UPM.  

```{r,echo=T}

#jackknife

jkn=as.svrepdesign(design=ps_pps,type='JKn', replicate=1000)


te_jkn=svyratio(~ingreso_hog, ~cant_personas,jkn,return.replicates=TRUE)

te_jkn

```
Luego, se estimó nuevamente el error estándar pero bajo el método de Bootstrap, con la variación de Rao-Wu, que se utiliza en diseños
aleatorios, estratificados y en varias etapas de selección, como es el caso. 

#TERMINAR


```{r,echo=T}
#Bootstrap
set.seed(1)

boot=as.svrepdesign(design=ps_pps, type='subbootstrap', replicates=1000)

te_boot=svyratio(~ingreso_hog, ~cant_personas,boot,return.replicates=TRUE)

te_boot 



```


**8. Realizar una visulización de la distribución empirica del estimador utilizando Bootstrap.**
**Interprete los resultados obtenidos.**

```{r, echo=FALSE,fig.cap="Gráfico 1: Este es el primer gráfico"}
tibble(est= te_boot$replicates) %>% ggplot()+
                                    geom_histogram(aes(x=est),bins=20,fill='orange',color='white') +
                                    theme_minimal() +
                                    geom_vline(aes(xintercept=mean(te_boot$replicates)), color="blue", linetype="dashed", linewidth=1) +
                                    geom_vline(aes(xintercept=median(te_boot$replicates)), color="red", linetype="dotted", linewidth=1) +
                                    labs(title="Histograma de ingreso per cápita",
                                         subtitle = "1000 réplicas realizadas bajo boostrap",
                                        x="Ratios",
                                        y="Frecuencia",
                                        caption="Asímetría: -0.04  Curtosis: 0.03") +
                                    theme(plot.title = element_text(hjust = 0.5, size = 20),
                                          axis.title.x = element_text(size = 15),                
                                          axis.title.y = element_text(size = 15),                
                                          axis.text.x = element_text(size = 12),                 
                                          axis.text.y = element_text(size = 12))                  


#asimetría
#skewness(te_boot$replicates)


#Curtosis
#kurtosis(te_boot$replicates)


```



**9. Estime la cantidad de personas pobres y no pobres (junto con sus márgenes de error).**
**Indique si los dominios de estimación son planeados o no planeados. Para este caso, utilice el Bootstrap realizado en los puntos anteriores.**
**Comente los resultados obtenidos y proponga estrategias para mejorar la precisión de la estimación obtenida.**

Vamos a emplear los dominios dentro de nuestra población correspondientes a *Pobres* y *No pobres*, la finalidad es poder realizar estimaciones ara estas subpoblaiones de interés. Por medio de la función *svyby* del paquete *Survey* es que estimamos los totales para cada subpoblación.


```{r,message=F,echo=F}



dominios = as.data.frame(svyby(~cant_personas , ~pobre , boot , svytotal)) %>%  
  rename(.,Cantidad_personas=cant_personas,SE=se,Pobre=pobre)%>%
  mutate(.,Pobre=ifelse(Pobre==1,"Pobre","No pobre"),
                        "2.5%"=Cantidad_personas-1.96*SE/sqrt(nrow(S)),
                        "97.5%"=Cantidad_personas+1.96*SE/sqrt(nrow(S))
         )

row.names(dominios)=NULL

dominios%>%
  kable()%>%
  kable_styling(position = "center", latex_options = "HOLD_position")%>%
  kable_classic_2()




```

```{r,message=F,echo=F}



ggplot(dominios, aes(x = Pobre, y = Cantidad_personas, fill = Pobre)) +
  geom_bar(stat = "identity", position = position_dodge(), color = "black") +
  geom_errorbar(aes(ymin = `2.5%`, ymax = `97.5%`), width = 0.2, position = position_dodge(0.9)) +
  labs(title = "Cantidad de Personas por Grupo (Pobre y No pobre)",
       x = "Grupo",
       y = "Cantidad de Personas") +
  theme_minimal() +
  theme(
    text = element_text(size = 15),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    plot.title = element_text(size = 16, hjust = 0.5),
    legend.position = "NONE"
  ) +
  scale_fill_manual(values = c("Pobre" = "red", "No pobre" = "blue"))



```



En nuestro caso los dominios no fueron planeados por lo tanto podemos recurrir a algunas estrategias para mejorar las estimaciones

- Aumentar la cantidad de iteraciones en el bootstrap.

Al aumentar el tamaño de la muestra en las iteraciones podemos asumir que experimentaremos una menor varianza en las estimaciones

```{r,message=F,echo=F}

#Aumentando la cantidad de replicas


set.seed(1)
boot_2000=as.svrepdesign(design=ps_pps, type='subbootstrap', replicates=2000)

dominios_2000 = as.data.frame(svyby(~cant_personas, ~pobre,boot_2000,svytotal)) %>% 
  rename(.,Cantidad_personas=cant_personas,SE=se,Pobre=pobre)%>%
  mutate(.,Pobre=ifelse(Pobre==1,"Pobre","No pobre"),
                        "2.5%"=Cantidad_personas-1.96*SE/sqrt(nrow(S)),
                        "97.5%"=Cantidad_personas+1.96*SE/sqrt(nrow(S))
         )


row.names(dominios_2000)=NULL


dominios_2000%>%
  kable()%>%
  kable_styling(position = "center", latex_options = "HOLD_position")%>%
  kable_classic_2()




```

El incremento en la cantidad de iteraciones no reduce la varinza en la estimación de los dominios.

- Ajustar los ponderadores mediante post-estratificación:

Acorde al trabajo realizado, contamos con la cantidad de personas pobres y no pobres en **U**, por lo que podemos ajustar los ponderadores con dicha información.

```{r}

data.frame("Cantidad de personas pobres y no pobres en U"=c("No pobre","Pobre"),
                           Frecuencia=c(sum(U$cant_personas)-sum(U$cant_personas*U$pobre),
                                        sum(U$cant_personas*U$pobre)
                                               ))%>%
  kable()%>%
  kable_styling(position = "center", latex_options = "HOLD_position")%>%
  kable_classic_2()




```

Procedemos a reponderar con la información disponible.

```{r, echo=T, message=F}

poblacion_pobre=data.frame(pobre=c(0,1),
           Freq=c(sum(U$cant_personas)-sum(U$cant_personas*U$pobre),
                                        sum(U$cant_personas*U$pobre)))


set.seed(1)
ps_pps_postestr = postStratify(boot, strata = ~pobre, population = poblacion_pobre) #Ponderadores ajustados por post-estratificacion

```

```{r, echo=F, message=F}


post_estrati = as.data.frame(svyby(~cant_personas, ~pobre, ps_pps_postestr, svytotal))%>% 
  rename(.,Cantidad_personas=cant_personas,SE=se,Pobre=pobre)%>%
  mutate(.,Pobre=ifelse(Pobre==1,"Pobre","No pobre"),
                        "2.5%"=Cantidad_personas-1.96*SE/sqrt(nrow(S)),
                        "97.5%"=Cantidad_personas+1.96*SE/sqrt(nrow(S))
         )

row.names(post_estrati)=NULL

post_estrati%>%
  kable()%>%
  kable_styling(position = "center", latex_options = "HOLD_position")%>%
  kable_classic_2()

```




# Conclusiones

- Comparacion entre los estimadores y los parametros



