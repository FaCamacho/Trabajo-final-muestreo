---
title: "Trabajo Final Muestreo"
author: "Fabricio Camacho y Luciana Viscailuz"
output: 
  html_document:
    fig_caption: true
date: "2024-06-18"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F,fig.cap = T)
```


<style>
.caption {
  text-align: center;
}
</style>

<style>
caption {
  caption-side: bottom;
  text-align: center;
}
</style>

# INTRODUCCIÓN


El objetivo de este proyecto es realizar estimaciones de diferentes parámetros a partir de varios de los metodos ya vistos en clase.
Para cumplir el objetivo la obtención de la muestra es una etapa clave, y para esta se comenzó seleccionando una muestra aleatoria de los hogares de Montevideo bajo un
diseño estratificado, por conglomerados y en dos etapas de selección. Siendo las UPM las manzanas y la USM los hogares.
Para la selección de las UPM y posteriormente las USM se combinaron diferentes diseños según lo pautado.
Finalmente, una vez obtenidas las muestras y las estimaciones se realizaron comparaciones obteniendo así diferentes conclusiones.



### Paquetes
```{r, warning=FALSE, message=FALSE, echo=T}
library(tidyverse)
library(survey)
library(srvyr)
library(sampling)
library(here)
library(kableExtra)
library(e1071)
library(moments)


options(scipen = 9999)

```

```{r,warning=FALSE, message=FALSE,}
U <- read_csv(here("Datos/Montevideo GR1.csv"))
```





# Analisis previo

```{r}

summary(U) %>%
  kable(.,caption="Tabla 1: Medidas de resumen") %>%
  kable_styling(position = "center", latex_options = "HOLD_position") %>%  kable_classic_2()

```
### Totales

Describir algo


```{r}
# computamos totales de las variables y N
pop_total = U %>% summarise(Total_personas=sum(cant_personas),
                 Desocupados=sum(desocupados),
                 Ocupados=sum(ocuopados),
                 Pobres=sum(pobre),
                 Total_hogares=n())%>%
                 kable(.,caption="Tabla 2: Totales de principales variables")%>%
                kable_styling(position = "center", latex_options = "HOLD_position") %>%  kable_classic_2()
pop_total

```

# RESULTADOS



**1. Calcule el tamano de muestra para obtener un margen de error de ±3% a un 95%**
**de confianza para estimar cualquier proporcion poblacional. Asuma un efecto de diseno de 1.5.**

Para obtener el tamaño de muestra para cualquier proporción se utilizó la formula:

  $$n = ((z^2 * p*(1-p))/moe^2)*moe  $$ 

Como se pedía un 95% de confianza, $\alpha$ tomó el valor de 0.05. Llevando a que $z_{(1-\sigma)}$  fuera el valor de la distribución normal en el cuantil 0.975.
Posteriormente se asumió que p tomaba el valor de 0.5 y se sustituyó moe (margen de error) por 0.03, tal como pide la letra.
Finalmente el tamaño de la muestra quedó en **1601**





```{r}

n = round((((1.96^2 * 0.5 * (1-0.5)) / 0.03^2) * 1.5 ),0)

```





**2. Con el tamano de muestra calculado en el punto anterior, asigne el mismo por estrato de forma optima, utilizando como variable auxiliar el ingreso del hogar.**

Se comenzó calculando para cada estrato su tamaño y las medidas de resumen (total, promedio y desvío) de la variable auxiliar, ingreso_hog.
Posteriormente, algunos de estos resultados fueron utilizados junto con el tamaño de muestra calculado en el punto anterior para obtener el tamaño de muestra de cada estrato según la asignación optima. 

$$n_h = n \\times \\frac{N_h \\text{sd}_{dU_h}[y]}{\\sum_{h=1}^{H} N_h \\text{sd}_{dU_h}[y]}$$

```{r}


U %>% 
  group_by(estrato) %>% 
  summarise(N=n(),
            tot_ing=sum(ingreso_hog),
            prom_ing=mean(ingreso_hog),
            sd_ig=sd(ingreso_hog),) %>%
            mutate(n_opt=round(n*N*sd_ig/sum(N*sd_ig),0))%>%
            rename(.,Estrato=estrato,
                   N_h=N,
                    Total_ingreso=tot_ing,
                   Promedio_ingreso=prom_ing,
                   SE_ingreso=sd_ig,
                   Tamaño_optimo=n_opt)%>%
            as.data.frame(.)%>%
                 kable(.,caption="Tabla 3: Tamaño de la muestra por asignacion estratificada según ingreso")%>%
                kable_styling(position = "center", latex_options = "HOLD_position") %>%  kable_classic_2()




```


```{r, echo=F}
tam = U %>% 
  group_by(estrato) %>% 
  summarise(N=n(),
            tot_ing=sum(ingreso_hog),
            prom_ing=mean(ingreso_hog),
            sd_ig=sd(ingreso_hog),) %>%
            mutate(n_opt=round(n*N*sd_ig/sum(N*sd_ig),0))%>%
            rename(.,N_h=N,
                    Total_ingreso=tot_ing,
                   Promedio_ingreso=prom_ing,
                   SE_ingreso=sd_ig,
                   Tamaño_optimo=n_opt)


```




**3. Seleccione una muestra bajo el diseño propuesto (aleatorio, estratificado, por conglomerados y en 2 etapas de selección).**
**Utilice como semilla el número de grupo al que pertenece.**


Para obtener la muestra final de hogares, se comenzó seleccionando m manzanas en cada estrato bajo un diseño PPS sin reemplazo, donde la probabilidad de que cada manzana fuera seleccionada dependía de la cantidad de personas que habitaban en ella, es decir, mientras mayor población existía en la manzana mayor probabilidad tenía esta de ser seleccionada. Dicho m se calculó tomando en cuenta el tamaño de muestra óptimo en cada estrato y que posteriormente se iban a extrarer cinco viviendas de cada manzana.

Obtenida la muestra de UPMs de cada estrato, se seleccionaron cinco viviendas de cada manzana bajo un diseño simple.

Finalmente, la muestra de hogares quedó conformada por cada uno de los cinco hogares extraídos de cada una de las manzanas seleccionadas de cada estrato. Se puede afirmar que en la muestra final hay hogares de los diferentes niveles socioeconomicos.



```{r, echo=T, message=F}


Muestra = list("Estrato 1"=0,"Estrato 2"=0,"Estrato 3"=0,"Estrato 4"=0,"Estrato 5"=0)

tamano= tam %>% as.data.frame(.)%>% select(.,Tamaño_optimo) %>% as.vector(.)


for(i in 1:5) {
  
#Primera etapa

m=round(tamano[["Tamaño_optimo"]][i]/5,0) #Cantidad de manzanas que se seleccionan de cada estrato

#Cantidad de personas por UPM (manzana)
U_upm_estrato = U %>% filter(,estrato==i) %>%  group_by(manzana) %>% summarise(MOS=sum(n())) %>% arrange(MOS)


#Se seleccionan m manzanas del estrato
set.seed(1)

s_upm=sampling::strata(data=U_upm_estrato,
                    stratanames = NULL,
                    size=m,
                    method='systematic',
                    pik=U_upm_estrato$MOS)

s_upm = getdata(U_upm_estrato,s_upm) %>% rename(prob_upm=Prob)


#Segunda etapa

#Se seleccionan bajo un Diseño simple 5 hogares de cada manzana seleccionada.

U_usm= U %>% left_join(s_upm %>% select(manzana,prob_upm)) %>% filter(is.na(prob_upm)==FALSE)

U_usm= U_usm %>% arrange(manzana)

set.seed(1)

s= sampling::strata(data=U_usm,
                    stratanames = 'manzana',
                    size=rep(5,m),
                    method='srswor')

s = getdata(U_usm,s) %>% rename(prob_usm=Prob)
  

Muestra[[i]]=s
  
}

S = tibble::as_tibble(rbind(Muestra[[1]],Muestra[[2]],Muestra[[3]],Muestra[[4]],Muestra[[5]])) %>%
  mutate(prob_total=prob_upm*prob_usm,
                w=1/prob_total)



```

**4. Calcule la estimacion puntual del ingreso promedio, proporcion de hogares pobres y total de personas ,a nivel de toda la población**

**Para cada estimacion se debe computar:**
 **- Error estandar (SE)**
 **- Coeficiente de variacion**
 **- Efecto de diseno**
 **- Margenes de error al 95%.**
 
**Interprete los resultados.**
 

Las estimaciones se realizaron tomando en cuenta la muestra final de hogares y los diseños con los que se trabajó.

$$ \hat Y_{HT}=\sum\limits_{i\in s} \frac{y_i}{\pi_i} $$ donde $$pi=n\frac{x_i}{\sum\limits_{i\in U}x_i}$$

#seguir


```{r,echo=F}

#Diseño estratificado en dos etapas 
ps_pps = S %>% svydesign(ids=~manzana+ID,
                        strata = ~estrato, 
                     weights=~w,
                     data=.)


#Ingreso promedio

ingreso_promedio_gorro = cross_join( as.data.frame(svymean(~ingreso_hog,ps_pps,deff=T)),
                                     as.data.frame(confint(svymean(~ingreso_hog,ps_pps,deff=T))))%>%
                          rename(.,Estimacion_puntual=mean,SE=ingreso_hog,Deff=deff)%>%
                              mutate(.,CV=SE/Estimacion_puntual)


#Proporcion de hogares pobres


hogares_pobres_gorro = cross_join( as.data.frame(svymean(~pobre,ps_pps,deff=T)),
                                     as.data.frame(confint(svymean(~pobre,ps_pps,deff=T))))%>%
                            rename(.,Estimacion_puntual=mean,SE=pobre,Deff=deff)%>%
                              mutate(.,CV=SE/Estimacion_puntual)


#Total de personas

total_personas_gorro = cross_join( as.data.frame(svytotal(~cant_personas,ps_pps,deff=T)),
                                     as.data.frame(confint(svytotal(~cant_personas,ps_pps,deff=T))))%>%
                          rename(.,Estimacion_puntual=total,SE=cant_personas,Deff=deff)%>%
                              mutate(.,CV=SE/(as.data.frame(svymean(~cant_personas,ps_pps,deff=T))$mean) )

#Totales

estimadores =round(rbind(ingreso_promedio_gorro,hogares_pobres_gorro,total_personas_gorro),3)%>%
  select(.,1,2,6,4,5,3)

rownames(estimadores) <- c("Ingreso promedio","Proporcion hogares pobres","Total de personas")

estimadores%>%
  kable(.,caption="Tabla 4: Estimadores de ingreso promedio, hogares pobres y total de personas")%>%
  kable_styling(position = "center", latex_options = "HOLD_position")%>%
  kable_classic_2()

```
 

**5. Para computar los errores estándar del punto anterior, ¿qué método para estimar varianza se utilizó?**

Para estimar la varianza se utilizó el método del último conglomerado junto con la linealización de Taylor. En este método se asume que la mayor variabilidad en la estimación proviene de la primera etapa del muestreo y que las manzanas (UPM) son seleccionadas con reposición. Luego el método de la linealización de Taylor realiza una aproximación lineal del estimador y permite estimar la varianza utilizando métodos para estimadores lineales.

Survey, el paquete que se utilizó en el punto anterior por defecto utiliza la formula: 

$$\hat V_{UC}=\frac{1}{n_I\n_I-1}\sum\limits_{i\in s_I}\(hat Y_i*-hat Y)**$$


 **6. Calcule el ingreso per cápita en Montevideo (junto con su error estándar).**
**Indique el tipo de parámetro y qué método fue utilizado por defecto por el paquete survey para la estimación del error estándar.**


En este punto se obtiene un estimador complejo denominado "Ratio", debido a que surge como cociente de dos totales, ingresos totales en Montevideo y cantidad de habitantes. Para realizar su estimación se debió contar previamente con la estimación de dichos totales.

Por defecto, el paquete survey utiliza la "Linealización de Taylor" y se aproxima $\\hat{\\theta}$, el parámetro de interés, por su desarrollo de primer orden. Como se utiliza una aproximación del parámetro, finalmente se obtiene la varianza del pseudo-estimador que es la que se conoce como la aproximación de la varianza.

$$\\hat{V}(\\hat{\\theta}) = \\sum_{i \\in s} \\sum_{j \\in s} \\frac{\\Delta_{ij}}{\\pi_{ij}} \\frac{\\hat{u}_i}{\\pi_i} \\frac{\\hat{u}_j}{\\pi_j}$$

Siendo $\\hat{u}_i=\sum\limits_{q=1}^Q\\hat{a}_q\y_qi  #CAMBIAR FORMULAS POR LA DE V(R)??

Al realizarle la raíz cuadrada a la estimación de la varianza se obtiene finalmente el $SE$.


```{r, echo=F,message=F}

# Calcular la estimación de razón


ratio_est <- svyratio(numerator = ~ingreso_hog,
                      denominator = ~cant_personas,
                      design = ps_pps)

Ingreso_percapita=bind_cols(as.data.frame(ratio_est$ratio),as.data.frame(sqrt(ratio_est$var)))%>%
  rename(Ingreso_Percapita=cant_personas...1,SE=cant_personas...2)

row.names(Ingreso_percapita)=NULL

Ingreso_percapita

```
**7. Calcule la estimación del error estándar del punto anterior, utilizando dos métodos de remuestreo: Jackknife y Bootstrap (con 1000 réplicas).**



Jackknife y Bootstrap son dos métodos de remuestreo que tienen como uno de sus objetivos obtener el $SE$ de estimadores no lineales.
La idea general de estos es que obtienen replicas de forma independiente a partir de la muestra original y posteriormente, para cada una de estas se calcula la estimación del parámetro. La varianza del estimador se obtiene a partir de observar la varianza entre las muestras.

Se comenzó realizando la estimación del error estándar bajo el método de Jackknife. Como el diseño es estratificado, se apliza Jackknife dentro de cada estrato. En este metodo se obtienen las réplicas eliminando de una unidad a la vez, en este caso, como el diseño es por conglomerados, eliminar una unidad se trauce en eliminar una UPM.  

```{r,echo=T}

#Jackknife

jkn=as.svrepdesign(design=ps_pps,type='JKn', replicate=1000)


te_jkn=svyratio(~ingreso_hog, ~cant_personas,jkn,return.replicates=TRUE)

te_jkn

```
Luego, se estimó nuevamente el error estándar pero bajo el método de Bootstrap, con la variación de Rao-Wu, que se utiliza en diseños
aleatorios, estratificados y en varia etapas de selección, como es el caso. En este método se obtienen replicas de cada estrato bajo un MAS y luego de varios calculos se obtienen diferentes estimaciones del parámetro de intrés, estas estimaciones se utilizan para calcular la varianza del estimador.



```{r,echo=T}
#Bootstrap
set.seed(1)

boot=as.svrepdesign(design=ps_pps, type='subbootstrap', replicates=1000)

te_boot=svyratio(~ingreso_hog, ~cant_personas,boot,return.replicates=TRUE)

te_boot 



```
## **Comparaciones:**

Tanto en el punto 6 como el 7 se obtuvieron estimaciones del ingreso per-capita y de su error estándar. 
La estimación del ingreso percapita fue la misma en los tres casos, la diferencia, aunque no mucha, surgió en la estimación del error estándar.
En todos los métodos las estimaciones se encuentran entre 37 y 38, siendo el método de Bootstrap el que obtuvo un menor %SE% con un valor de 37.54098, y Jackknife el mayor con 37.88454. En conlusión, si existe una diferencia entre las estimaciones de los métodos pero por lo menos en este caso dichas diferencias no son muy importantes.




**8. Realizar una visulización de la distribución empirica del estimador utilizando Bootstrap.**
**Interprete los resultados obtenidos.**

```{r, echo=FALSE,fig.cap="Gráfico 1: 1000 réplicas realizadas bajo boostrap"}
tibble(est= te_boot$replicates) %>% ggplot()+
                                    geom_histogram(aes(x=est),bins=20,fill='orange',color='white') +
                                    theme_minimal() +
                                    geom_vline(aes(xintercept=mean(te_boot$replicates)), color="blue", linetype="dashed", linewidth=1) +
                                    geom_vline(aes(xintercept=median(te_boot$replicates)), color="red", linetype="dotted", linewidth=1) +
                                    labs(title="Histograma de ingreso per cápita",
                                         subtitle = "",
                                        x="Ratios",
                                        y="Frecuencia",
                                        caption="Asímetría: -0.04  Curtosis: 0.03") +
                                    theme(plot.title = element_text(hjust = 0.5, size = 20),
                                          axis.title.x = element_text(size = 15),                
                                          axis.title.y = element_text(size = 15),                
                                          axis.text.x = element_text(size = 12),                 
                                          axis.text.y = element_text(size = 12))                  


#asimetría
#skewness(te_boot$replicates)


#Curtosis
#kurtosis(te_boot$replicates)-3


```



**9. Estime la cantidad de personas pobres y no pobres (junto con sus márgenes de error).**
**Indique si los dominios de estimación son planeados o no planeados. Para este caso, utilice el Bootstrap realizado en los puntos anteriores.**
**Comente los resultados obtenidos y proponga estrategias para mejorar la precisión de la estimación obtenida.**

(Escribir algo sobre los dominios)

```{r,message=F,echo=F}



dominios = as.data.frame(svyby(~cant_personas , ~pobre , boot , svytotal)) %>%  
  rename(.,Cantidad_personas=cant_personas,SE=se,Pobre=pobre)%>%
  mutate(.,Pobre=ifelse(Pobre==1,"Pobre","No pobre"),
                        "2.5%"=Cantidad_personas-1.96*SE/sqrt(nrow(S)),
                        "97.5%"=Cantidad_personas+1.96*SE/sqrt(nrow(S))
         )

row.names(dominios)=NULL

dominios%>%
  kable(.,caption="Tabla 5: Estimación del total de personas para los dominios de 'Pobre' y 'No pobre' ")%>%
  kable_styling(position = "center", latex_options = "HOLD_position")%>%
  kable_classic_2()




```

```{r,message=F,echo=F,fig.cap="Gráfico 2: Estimación por dominios"}

  

ggplot(dominios, aes(x = Pobre, y = Cantidad_personas, fill = Pobre)) +
  geom_bar(stat = "identity", position = position_dodge(), color = "black") +
  geom_errorbar(aes(ymin = `2.5%`, ymax = `97.5%`), width = 0.2, position = position_dodge(0.9)) +
  labs(title = "Cantidad de Personas por Grupo (Pobre y No pobre)",
       x = "Grupo",
       y = "Cantidad de Personas") +
  theme_minimal() +
  theme(
    text = element_text(size = 15),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14),
    plot.title = element_text(size = 16, hjust = 0.5),
    legend.position = "NONE"
  ) +
  scale_fill_manual(values = c("Pobre" = "red", "No pobre" = "blue"))



```



Los dominios no fueron planeados.
Para mejorar las estimaciones se podría:

- Aumentar la cantidad de iteraciones en el bootstrap


```{r,message=F,echo=F}

#Aumentando la cantidad de replicas


set.seed(1)
boot_2000=as.svrepdesign(design=ps_pps, type='subbootstrap', replicates=2000)

dominios_2000 = as.data.frame(svyby(~cant_personas, ~pobre,boot_2000,svytotal)) %>% 
  rename(.,Cantidad_personas=cant_personas,SE=se,Pobre=pobre)%>%
  mutate(.,Pobre=ifelse(Pobre==1,"Pobre","No pobre"),
                        "2.5%"=Cantidad_personas-1.96*SE/sqrt(nrow(S)),
                        "97.5%"=Cantidad_personas+1.96*SE/sqrt(nrow(S))
         )


row.names(dominios_2000)=NULL


dominios_2000%>%
  kable()%>%
  kable_styling(position = "center", latex_options = "HOLD_position")%>%
  kable_classic_2()

te_boot2000=svyratio(~ingreso_hog, ~cant_personas,boot_2000,return.replicates=TRUE)


```


```{r, echo=FALSE,fig.cap="Gráfico 3: 2000 réplicas realizadas bajo boostrap"}
tibble(est= te_boot2000$replicates) %>% ggplot()+
                                    geom_histogram(aes(x=est),bins=20,fill='orange',color='white') +
                                    theme_minimal() +
                                    geom_vline(aes(xintercept=mean(te_boot2000$replicates)), color="blue", linetype="dashed", linewidth=1) +
                                    geom_vline(aes(xintercept=median(te_boot2000$replicates)), color="red", linetype="dotted", linewidth=1) +
                                    labs(title="Histograma de ingreso per cápita",
                                         subtitle = "",
                                        x="Ratios",
                                        y="Frecuencia",
                                        caption="Asímetría: -0.09  Curtosis: 0.36") +
                                    theme(plot.title = element_text(hjust = 0.5, size = 20),
                                          axis.title.x = element_text(size = 15),                
                                          axis.title.y = element_text(size = 15),                
                                          axis.text.x = element_text(size = 12),                 
                                          axis.text.y = element_text(size = 12))                  


#asimetría
#skewness(te_boot2000$replicates)


#Curtosis
#kurtosis(te_boot2000$replicates)-3


```

En lo que respecta a esta estrategia no mejora las estimaciones.


- Ajustar los ponderadores mediante post-estratificación:

```{r, echo=T, message=F}


poblacion_pobre = U  %>% group_by(.,pobre) %>% summarise(Freq = n()) #Frecuencias poblacionales de pobres


ps_pps_postestr = postStratify(boot, strata = ~pobre, population = poblacion_pobre) #Ponderadores ajustados por post-estratificacion

```

```{r, echo=F, message=F}


post_estrati = as.data.frame(svyby(~cant_personas, ~pobre, ps_pps_postestr, svytotal))%>% 
  rename(.,Cantidad_personas=cant_personas,SE=se,Pobre=pobre)%>%
  mutate(.,Pobre=ifelse(Pobre==1,"Pobre","No pobre"),
                        "2.5%"=Cantidad_personas-1.96*SE/sqrt(nrow(S)),
                        "97.5%"=Cantidad_personas+1.96*SE/sqrt(nrow(S))
         )

row.names(post_estrati)=NULL

post_estrati%>%
  kable()%>%
  kable_styling(position = "center", latex_options = "HOLD_position")%>%
  kable_classic_2()

```


# Conclusiones

- Comparacion entre los estimadores y los parametros



